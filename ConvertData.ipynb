{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa de Transformação de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "#import io\n",
    "\n",
    "home = Path.home()\n",
    "correct_path = Path(home, \"Documents\")\n",
    "    \n",
    "# Downloading csv file from your GitHub account\n",
    "url = \"https://github.com/alemattos-cmd/rox_case/archive/refs/heads/main.zip\" \n",
    "download = requests.get(url, allow_redirects=True)\n",
    "with open(correct_path.joinpath(\"rox_case-main.zip\"), \"wb\") as code:\n",
    "    code.write(download.content)\n",
    "\n",
    "# Extract data from zipfile\n",
    "def un_zipFiles(correct_path):\n",
    "    files=os.listdir(correct_path)\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            filePath=correct_path.joinpath(file)\n",
    "            zip_file = zipfile.ZipFile(filePath)\n",
    "            for names in zip_file.namelist():\n",
    "                zip_file.extract(names,correct_path)\n",
    "            zip_file.close()\n",
    "        #file.close()\n",
    "            \n",
    "un_zipFiles(correct_path)\n",
    "\n",
    "#update path\n",
    "correct_path = Path(correct_path, \"rox_case-main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação do arquivo 'Person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_person = pd.read_csv(\"Person.Person.csv\", delimiter=\";\")\n",
    "df_person = df_person.drop(columns=['NameStyle', 'Title', 'AdditionalContactInfo','rowguid', 'ModifiedDate'])\n",
    "\n",
    "df_person.insert(8,'BirthDate', 'null', True)\n",
    "df_person = df_person.astype(\"string\")\n",
    "df_person.insert(9,'TotalPurchase', 0, True)\n",
    "\n",
    "df_person['BusinessEntityID'] = pd.to_numeric(df_person['BusinessEntityID'], errors='coerce')\n",
    "df_person['EmailPromotion'] = pd.to_numeric(df_person['EmailPromotion'], errors='coerce')\n",
    "\n",
    "#df_person.fillna(value='null')\n",
    "\n",
    "t = df_person['Demographics'].values\n",
    "d= t.copy()\n",
    "\n",
    "## Extract TotalPurchase from a list of Demographics information\n",
    "pattern = \"<TotalPurchaseYTD>(.*?)</TotalPurchaseYTD>\"\n",
    "i=0\n",
    "for s in t:\n",
    "    totalpurchase = re.search(pattern, s).group(1)\n",
    "    t[i] = totalpurchase\n",
    "    i=i+1\n",
    "    \n",
    "df_person['TotalPurchase'] = t.astype(\"float64\")\n",
    "\n",
    "## Extract BirthDate from copy list of Demographics information\n",
    "pattern2 = \"<BirthDate>(.*?)Z</BirthDate>\"\n",
    "j=0\n",
    "for g in d:\n",
    "    if (re.search(pattern2, g)) != None:\n",
    "        BirthDate=re.search(pattern2, g).group(1)\n",
    "        d[j]=BirthDate\n",
    "        j=j+1\n",
    "    else:\n",
    "        d[j] = 'null'\n",
    "        j=j+1\n",
    "        \n",
    "df_person['BirthDate'] = d\n",
    "df_person['BirthDate'] = pd.to_datetime(df_person['BirthDate'], errors='coerce')\n",
    "df_person = df_person.drop(columns=['Demographics'])\n",
    "\n",
    "# processing missing data\n",
    "df_person.update(df_person['MiddleName'].fillna(''))\n",
    "df_person.update(df_person['Suffix'].fillna(''))\n",
    "#df_person.update(df_person['BirthDate'].fillna(''))\n",
    "\n",
    "#print(df_person.isnull().sum())\n",
    "#(df_person.info())\n",
    "#display(df_person)\n",
    "df_person.to_csv(correct_path.joinpath('Person.csv'),index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação do arquivo 'Customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = pd.read_csv(\"Sales.Customer.csv\", delimiter=\";\" )\n",
    "df_customer = df_customer.drop(columns=['rowguid', 'ModifiedDate'])\n",
    "\n",
    "df_customer.fillna(value='null')\n",
    "df_customer['AccountNumber'] = df_customer['AccountNumber'].astype(\"string\")\n",
    "\n",
    "#print(df_customer.isnull().sum())\n",
    "#(df_customer.info())\n",
    "#display(df_customer)\n",
    "\n",
    "df_customer.to_csv(correct_path.joinpath('Customer.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação do arquivo 'SalesOrderHeader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_header = pd.read_csv(\"Sales.SalesOrderHeader.csv\", delimiter=\";\")\n",
    "df_header = df_header.drop(columns=['Status', 'Comment','rowguid', 'ModifiedDate'])\n",
    "\n",
    "df_customer.fillna(value='null')\n",
    "\n",
    "c = ['CreditCardID', 'SalesPersonID', 'CurrencyRateID']\n",
    "for colun in c:\n",
    "    df_header[colun] = df_header[colun].apply(lambda x: int(x) if x == x else None)\n",
    "\n",
    "df_header['OrderDate'] = pd.to_datetime(df_header['OrderDate'])\n",
    "df_header['DueDate'] = pd.to_datetime(df_header['DueDate'])\n",
    "df_header['ShipDate'] = pd.to_datetime(df_header['ShipDate'])\n",
    "df_header['SalesOrderNumber'] = df_header['SalesOrderNumber'].astype(\"string\")\n",
    "df_header['PurchaseOrderNumber'] = df_header['PurchaseOrderNumber'].astype(\"string\")\n",
    "df_header['AccountNumber'] = df_header['AccountNumber'].astype(\"string\")\n",
    "df_header['CreditCardApprovalCode'] = df_header['CreditCardApprovalCode'].astype(\"string\")\n",
    "\n",
    "\n",
    "df_header[\"SubTotal\"] = [(str(w).replace(\" \", \"\")) for w in df_header[\"SubTotal\"]]\n",
    "df_header[\"SubTotal\"] = [(str(w).replace(\",\" , \".\")) for w in df_header[\"SubTotal\"]]\n",
    "df_header['SubTotal'] = pd.to_numeric(df_header['SubTotal'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "df_header[\"TaxAmt\"] = [(str(w).replace(\" \", \"\")) for w in df_header[\"TaxAmt\"]]\n",
    "df_header[\"TaxAmt\"] = [(str(w).replace(\",\" , \".\")) for w in df_header[\"TaxAmt\"]]\n",
    "df_header['TaxAmt'] = pd.to_numeric(df_header['TaxAmt'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "df_header[\"Freight\"] = [(str(w).replace(\" \", \"\")) for w in df_header[\"Freight\"]]\n",
    "df_header[\"Freight\"] = [(str(w).replace(\",\" , \".\")) for w in df_header[\"Freight\"]]\n",
    "df_header['Freight'] = pd.to_numeric(df_header['Freight'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "df_header[\"TotalDue\"] = [(str(w).replace(\" \", \"\")) for w in df_header[\"TotalDue\"]]\n",
    "df_header[\"TotalDue\"] = [(str(w).replace(\",\" , \".\")) for w in df_header[\"TotalDue\"]]\n",
    "df_header['TotalDue'] = pd.to_numeric(df_header['TotalDue'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "#print(df_header.isnull().sum())\n",
    "#(df_header.info())\n",
    "#display(df_header)\n",
    "df_header.to_csv(correct_path.joinpath('SalesOrderHeader.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação do arquivo 'SalesOrderDetail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detail = pd.read_csv(\"Sales.SalesOrderDetail.csv\", delimiter=\";\" )\n",
    "df_detail = df_detail.drop(columns=['rowguid', 'ModifiedDate'])\n",
    "\n",
    "df_detail['CarrierTrackingNumber'] = df_detail['CarrierTrackingNumber'].astype(\"string\")\n",
    "df_detail[\"UnitPrice\"] = [(str(w).replace(\" \", \"\")) for w in df_detail[\"UnitPrice\"]]\n",
    "df_detail[\"UnitPrice\"] = [(str(w).replace(\",\" , \".\")) for w in df_detail[\"UnitPrice\"]]\n",
    "df_detail['UnitPrice'] = pd.to_numeric(df_detail['UnitPrice'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "df_detail[\"UnitPriceDiscount\"] = [(str(w).replace(\" \", \"\")) for w in df_detail[\"UnitPriceDiscount\"]]\n",
    "df_detail[\"UnitPriceDiscount\"] = [(str(w).replace(\",\" , \".\")) for w in df_detail[\"UnitPriceDiscount\"]]\n",
    "df_detail['UnitPriceDiscount'] = pd.to_numeric(df_detail['UnitPriceDiscount'], errors=\"coerce\").map(\"{:.2f}\".format).astype(float)\n",
    "\n",
    "#print(df_detail.isnull().sum())\n",
    "#(df_detail.info())\n",
    "#display(df_detail)\n",
    "df_detail.to_csv(correct_path.joinpath('SalesOrderDetail.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação do arquivo 'SpecialOfferProduct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_special = pd.read_csv(\"Sales.SpecialOfferProduct.csv\", delimiter=\";\" )\n",
    "df_special = df_special.drop(columns=['rowguid', 'ModifiedDate'])\n",
    "\n",
    "#(df_special.info())\n",
    "#display(df_special)\n",
    "df_special.to_csv(correct_path.joinpath('SpecialOfferProduct.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparação do arquivo 'Product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_product = pd.read_csv(\"Production.Product.csv\", delimiter=\";\" )\n",
    "df_product = df_product.drop(columns=['DiscontinuedDate','rowguid', 'ModifiedDate'])\n",
    "\n",
    "c = ['Name', 'ProductNumber', 'Color', 'Size', 'SizeUnitMeasureCode', 'WeightUnitMeasureCode', 'ProductLine', 'Class', 'Style']\n",
    "for colun in c:\n",
    "    df_product[colun] = df_product[colun].astype(\"string\")\n",
    "    \n",
    "\n",
    "df_product[\"StandardCost\"] = [(str(w).replace(\" \", \"\")) for w in df_product[\"StandardCost\"]]\n",
    "df_product[\"StandardCost\"] = [(str(w).replace(\",\" , \".\")) for w in df_product[\"StandardCost\"]]\n",
    "df_product['StandardCost'] = pd.to_numeric(df_product['StandardCost'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "df_product[\"ListPrice\"] = [(str(w).replace(\" \", \"\")) for w in df_product[\"ListPrice\"]]\n",
    "df_product[\"ListPrice\"] = [(str(w).replace(\",\" , \".\")) for w in df_product[\"ListPrice\"]]\n",
    "df_product['ListPrice'] = pd.to_numeric(df_product['ListPrice'], errors=\"coerce\").map(\"{:.4f}\".format).astype(float)\n",
    "\n",
    "df_product['SellStartDate'] = pd.to_datetime(df_product['SellStartDate'], errors='coerce')\n",
    "df_product['SellEndDate'] = pd.to_datetime(df_product['SellEndDate'], errors='coerce')\n",
    "\n",
    "#print(df_product.isnull().sum())\n",
    "#(df_product.info())\n",
    "#display(df_product)\n",
    "df_product.to_csv(correct_path.joinpath('Product.csv'),index=False)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
